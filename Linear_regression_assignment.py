# -*- coding: utf-8 -*-
"""Linear Regression Assignment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nseSy9kRJBFxXXnFO0Y5Nm1ykivE0v2h
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
import statsmodels.api as sm
from sklearn.metrics import r2_score
from sklearn.feature_selection import RFE

"""## Data Reading and Understanding"""

df = pd.read_csv("/content/day.csv")
df.head()

df = df.drop(["dteday","instant","registered","casual"], axis = 1) # derived metrics are already there

# Map
season_mapping = {1: 'Spring', 2: 'Summer', 3: 'Fall', 4: 'Winter'}

# Apply
df["season"] = df["season"].map(season_mapping)

# Map
weather_mapping = {
    1: 'Clear, Few clouds, Partly cloudy, Partly cloudy',
    2: 'Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist',
    3: 'Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds',
    4: 'Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog'
}

# Apply
df['weathersit'] = df['weathersit'].map(weather_mapping)

# Map
yr_mapping = {
    0: 2018,
    1: 2019,
}

# Apply
df['yr'] = df['yr'].map(yr_mapping)

# Check for any missing values
df.isnull().sum()

"""## EDA

### Univaritate
"""

cat_cols = ["season","mnth", "holiday","weekday","workingday","weathersit"]
num_cols = ["temp","yr","atemp","hum", "windspeed"]

for col in cat_cols:
    df[col] = df[col].astype('category')
    plt.figure(figsize=(10, 3))
    ax = sns.countplot(x=df[col])
    plt.xticks(rotation=90)

    # Add count values on top of each bar
    for p in ax.patches:
        ax.annotate(format(p.get_height(), '.0f'),
                    (p.get_x() + p.get_width() / 2., p.get_height()),
                    ha = 'center', va = 'center', xytext = (0, 5), textcoords = 'offset points')

    plt.show()

# univariate analysis of numerical columns
for col in num_cols:

    # Create boxplot
    sns.boxplot(data=df, x=col)

    # Calculate median and IQR
    median = df[col].median()
    q1 = df[col].quantile(0.25)
    q3 = df[col].quantile(0.75)

    # Annotate plot with median and IQR values
    #plt.text(0, median + 0.5, f'Median: {median:.2f}\nq1: {q1:.2f}\nq3: {q3:.2f}', horizontalalignment='center', size='medium', color='black', weight='semibold')
    print(f'Median: {median:.2f}\nq1: {q1:.2f}\nq3: {q3:.2f}')
    plt.show()

"""### Bivariate Analysis"""

# bivariate analysis of numerical columns
for i in range(len(num_cols)):
    for j in range(i+1, len(num_cols)):
        #sns.scatterplot(x=df[num_cols[i]], y=df[num_cols[j]])
        sns.regplot(x=df[num_cols[i]], y=df[num_cols[j]], scatter_kws={"s": 5})  # scatter_kws sets the size of the points
        plt.show()

# categorical vs numerical column bivariate analysis
for col1 in cat_cols:
    df = df.sort_values(by=col1)
    for col2 in num_cols:
        sns.boxplot(x=df[col1], y=df[col2])

        # Calculate median and IQR
        medians = df.groupby([col1])[col2].median().values
        q1 = df.groupby([col1])[col2].quantile(0.25).values
        q3 = df.groupby([col1])[col2].quantile(0.75).values

        # Annotate plot with median and IQR values
        for i in range(len(medians)):
            print(f'Median: {medians[i]:.2f}\nq1: {q1[i]:.2f}\nq3: {q3[i]:.2f}')
        plt.xticks(rotation=90)
        plt.show()

"""### Multivariate analysis"""

# Create dummy variables for the season column
season_dummies = pd.get_dummies(df['season'], prefix='season', drop_first=True)

# Concatenate the dummy variables with the original dataframe
df = pd.concat([df, season_dummies], axis=1)

# Create dummy variables for the season column
weathersit_dummies = pd.get_dummies(df['weathersit'], prefix='weathersit', drop_first=True)

# Concatenate the dummy variables with the original dataframe
df = pd.concat([df, weathersit_dummies], axis=1)

# Drop the original columns
df = df.drop(["season","weathersit"],axis = 1)

plt.figure(figsize=[10,6])
sns.heatmap(df.corr(),annot=True, cmap="Greens", fmt=".2f")
plt.show()

"""## Split the train test dataset"""

df_train, df_test = train_test_split(df, train_size = 0.7, random_state = 100)
print(df_train.shape)
print(df_test.shape)

"""## Scale the data"""

scaler = MinMaxScaler()

df_train[df_train.columns]= scaler.fit_transform(df_train[df_train.columns])
df_test[df_test.columns]= scaler.transform(df_test[df_test.columns])
df_test.head()

"""X_train, y_train"""

y_train = df_train.pop("cnt")
X_train = df_train

y_test = df_test.pop("cnt")
X_test = df_test

y_train.head()

df.columns

"""### RFE"""

model = LinearRegression()

# Initialize RFE
rfe = RFE(model, n_features_to_select=11)  # Select top 12 features

# Fit RFE
rfe.fit(X_train, y_train)

# Get selected features
selected_features = rfe.support_

list(zip(X_train.columns,rfe.support_, rfe.ranking_))

input_columns = X_train.columns[rfe.support_]

# Fit linear regression model using selected features
def LinearRegressionModel(X, y, input_columns):
  X_sm = sm.add_constant(X[input_columns])
  lr_model = sm.OLS(y, X_sm).fit()
  return lr_model

lr_model = LinearRegressionModel(X_train, y_train, input_columns)
# Get the slope (coefficients) and intercept
lr_model.params

lr_model.summary()

# Remove the one with high P Value or the correlated vars
# Columns to remove
columns_to_remove = ["mnth"]
# Create a boolean mask to select elements that are not in columns_to_remove
mask = np.logical_not(np.isin(input_columns, columns_to_remove))

# Create a new array with elements not in columns_to_remove
input_columns_1 = input_columns[mask]
print(input_columns_1)
# Fit linear regression model using selected features
lr_model = LinearRegressionModel(X_train, y_train, input_columns_1)

# Get the slope (coefficients) and intercept
lr_model.params

lr_model.summary()

from statsmodels.stats.outliers_influence import variance_inflation_factor

# Assuming X_train is your training data
# Assuming lr_model is your linear regression model from statsmodels

# Get the design matrix (including the constant if present)
X_train_with_const = sm.add_constant(X_train[input_columns_1])

# Calculate VIF for each feature
vif = [variance_inflation_factor(X_train_with_const.values, i) for i in range(X_train_with_const.shape[1])]

# Create a DataFrame to display the VIF values
vif_df = pd.DataFrame({'Feature': X_train_with_const.columns, 'VIF': vif})

print(vif_df)

#R-Value for test set

# add a constant to X_test
X_test_sm = sm.add_constant(X_test[input_columns_1])
y_test_pred = lr_model.predict(X_test_sm)

r2_score(y_test, y_test_pred)